SESSION_SECRET_KEY="a-secret-key"
SYNC_DATABASE_URL="sqlite:///./app.db"
ASYNC_DATABASE_URL="sqlite+aiosqlite:///./app.db"
PYTHONDONTWRITEBYTECODE=1

# LM Studio Configuration (OpenAI-compatible local server)
# Make sure LM Studio is running with a model loaded on the local server
# Default LM Studio server runs at http://localhost:1234
LLM_PROVIDER="llama_index.llms.openai_like.OpenAILike"
LLM_BASE_URL="http://localhost:1234/v1"
# The model name can be "local-model" or any identifier - LM Studio uses whatever model is loaded
LL_MODEL="local-model"
# LM Studio doesn't require an API key for local server
LLM_API_KEY="not-needed"

# Embedding Configuration
# Option 1: Use OpenAI for embeddings (requires API key and credits)
# EMBEDDING_PROVIDER="openai"
# EMBEDDING_API_KEY="your-openai-api-key-here"
# EMBEDDING_MODEL="text-embedding-3-small"

# Option 2: Use LM Studio for embeddings (if your model supports it)
EMBEDDING_PROVIDER="llama_index.embeddings.openai_like.OpenAILikeEmbedding"
EMBEDDING_BASE_URL="http://localhost:1234/v1"
EMBEDDING_MODEL="local-embedding-model"
EMBEDDING_API_KEY="not-needed"

# Alternative: If you prefer to use Ollama instead of LM Studio, uncomment below:
# LLM_PROVIDER="ollama"
# LL_MODEL="gemma3:4b"
# EMBEDDING_PROVIDER="ollama"
# EMBEDDING_MODEL="dengcao/Qwen3-Embedding-0.6B:Q8_0"
